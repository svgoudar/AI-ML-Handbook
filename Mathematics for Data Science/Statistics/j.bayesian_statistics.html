
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Bayesian Statistics: Concepts and Applications &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Mathematics for Data Science/Statistics/j.bayesian_statistics';</script>
    <link rel="icon" href="../../_static/logo.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../markdown.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../table_of_contents.html">Table of Contents</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/edit/master/docs/Mathematics for Data Science/Statistics/j.bayesian_statistics.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FMathematics for Data Science/Statistics/j.bayesian_statistics.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/Mathematics for Data Science/Statistics/j.bayesian_statistics.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Bayesian Statistics: Concepts and Applications</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Bayesian Statistics: Concepts and Applications</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concepts">1. Concepts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-probability-p-h">1.1. Prior Probability (<span class="math notranslate nohighlight">\(P(H)\)</span>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood-p-e-h">1.2. Likelihood (<span class="math notranslate nohighlight">\(P(E|H)\)</span>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-probability-p-h-e">1.3. Posterior Probability (<span class="math notranslate nohighlight">\(P(H|E)\)</span>)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applications">2. Applications</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-rule-in-inference">2.1. Bayes’ Rule in Inference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-problem-statement-medical-diagnosis"><strong>Example Problem Statement (Medical Diagnosis):</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-b-testing-bayesian-approach">2.2. A/B Testing (Bayesian Approach)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-problem-statement-website-conversion"><strong>Example Problem Statement (Website Conversion):</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-making-under-uncertainty">2.3. Decision Making Under Uncertainty</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-problem-statement-investment-decision"><strong>Example Problem Statement (Investment Decision):</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-decision-making-conceptual-plot"><strong>Visualizing Decision Making (Conceptual Plot):</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#a-b-testing-metrics-and-methodologies">A/B Testing Metrics and Methodologies</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lift-p-values-conversion-rates">1. Lift, p-values, Conversion Rates</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversion-rate">1.1. Conversion Rate</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lift-relative-increase">1.2. Lift (Relative Increase)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#p-value">1.3. p-value</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement-manual-calculation-conversion-rate-lift"><strong>Problem Statement &amp; Manual Calculation (Conversion Rate &amp; Lift):</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-testing-vs-fixed-horizon-testing">2. Sequential Testing vs. Fixed Horizon Testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fixed-horizon-testing-traditional-a-b-testing">2.1. Fixed Horizon Testing (Traditional A/B Testing)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptual-problem-statement-fixed-horizon"><strong>Conceptual Problem Statement (Fixed Horizon):</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-testing-continuous-monitoring">2.2. Sequential Testing (Continuous Monitoring)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptual-problem-statement-sequential-testing"><strong>Conceptual Problem Statement (Sequential Testing):</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptual-plot-fixed-horizon-vs-sequential-testing"><strong>Conceptual Plot: Fixed Horizon vs. Sequential Testing</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-estimation-mle-and-resampling-techniques">Maximum Likelihood Estimation (MLE) and Resampling Techniques</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-estimation-mle">1. Maximum Likelihood Estimation (MLE)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explanation">Explanation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-intuition">Mathematical Intuition</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resampling-techniques">2. Resampling Techniques</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrapping">2.1. Bootstrapping</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-problem-statement-estimating-confidence-interval-for-median-income-bootstrap"><strong>Example Problem Statement: Estimating Confidence Interval for Median Income (Bootstrap)</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jackknife-resampling">2.2. Jackknife Resampling</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-problem-statement-estimating-bias-and-standard-error-of-the-mean-jackknife"><strong>Example Problem Statement: Estimating Bias and Standard Error of the Mean (Jackknife)</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="bayesian-statistics-concepts-and-applications">
<h1>Bayesian Statistics: Concepts and Applications<a class="headerlink" href="#bayesian-statistics-concepts-and-applications" title="Link to this heading">#</a></h1>
<p>Bayesian statistics provides a framework for updating our beliefs about a hypothesis as new evidence becomes available. It’s fundamentally different from frequentist statistics in its philosophical approach to probability, treating probability as a measure of belief rather than a long-run frequency.</p>
<section id="concepts">
<h2>1. Concepts<a class="headerlink" href="#concepts" title="Link to this heading">#</a></h2>
<p>At the heart of Bayesian statistics are three key concepts: Prior, Likelihood, and Posterior. These are related by Bayes’ Theorem.</p>
<section id="prior-probability-p-h">
<h3>1.1. Prior Probability (<span class="math notranslate nohighlight">\(P(H)\)</span>)<a class="headerlink" href="#prior-probability-p-h" title="Link to this heading">#</a></h3>
<p>The <strong>Prior Probability</strong> (or simply “Prior”) represents your initial belief about the probability of a hypothesis (<span class="math notranslate nohighlight">\(H\)</span>) being true, <em>before</em> observing any new data or evidence (<span class="math notranslate nohighlight">\(E\)</span>). It’s your current state of knowledge or uncertainty.</p>
<ul class="simple">
<li><p><strong>Subjectivity:</strong> Priors can be subjective (based on expert opinion, past experience, or intuition) or objective (chosen to be uninformative or to reflect existing data).</p></li>
<li><p><strong>Purpose:</strong> It quantifies what you already know (or assume) about the parameter or hypothesis of interest.</p></li>
</ul>
<p><strong>Example:</strong></p>
<ul class="simple">
<li><p>You believe there’s a 10% chance a new marketing campaign will increase sales by more than 20%.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
P(\text{Sales Increase &gt; 20\%}) = 0.10
\]</div>
<ul class="simple">
<li><p>You think a specific coin is fair, so <span class="math notranslate nohighlight">\(P(\text{Heads}) = 0.5\)</span>.</p></li>
</ul>
</section>
<section id="likelihood-p-e-h">
<h3>1.2. Likelihood (<span class="math notranslate nohighlight">\(P(E|H)\)</span>)<a class="headerlink" href="#likelihood-p-e-h" title="Link to this heading">#</a></h3>
<p>The <strong>Likelihood</strong> is the probability of observing the new evidence (<span class="math notranslate nohighlight">\(E\)</span>), <em>given that the hypothesis (<span class="math notranslate nohighlight">\(H\)</span>) is true</em>. It quantifies how well the hypothesis explains the observed data.</p>
<ul class="simple">
<li><p><strong>Important Note:</strong> The likelihood is <em>not</em> a probability of the hypothesis. It’s the probability of the <em>data</em> under the assumption of the hypothesis.</p></li>
<li><p><strong>Calculation:</strong> This is typically derived from the data-generating process or a statistical model, assuming <span class="math notranslate nohighlight">\(H\)</span> is true.</p></li>
</ul>
<p><strong>Example (continuing from above):</strong></p>
<ul class="simple">
<li><p>If the marketing campaign <em>did</em> increase sales by more than 20% (H), what’s the probability of observing your specific sales data (E)? Or, if the campaign <em>did not</em> increase sales (H_not), what’s the probability of observing that data?</p></li>
<li><p>If the coin <em>is</em> fair (<span class="math notranslate nohighlight">\(H: P(\text{Heads})=0.5\)</span>), what’s the probability of observing 7 heads in 10 flips (<span class="math notranslate nohighlight">\(E\)</span>)?</p></li>
</ul>
</section>
<section id="posterior-probability-p-h-e">
<h3>1.3. Posterior Probability (<span class="math notranslate nohighlight">\(P(H|E)\)</span>)<a class="headerlink" href="#posterior-probability-p-h-e" title="Link to this heading">#</a></h3>
<p>The <strong>Posterior Probability</strong> (or simply “Posterior”) is the updated probability of the hypothesis (<span class="math notranslate nohighlight">\(H\)</span>) being true, <em>after</em> considering the new evidence (<span class="math notranslate nohighlight">\(E\)</span>). It’s your revised belief, taking into account both your prior knowledge and the new data.</p>
<ul class="simple">
<li><p><strong>The Goal:</strong> This is often the ultimate goal of Bayesian inference – to update our beliefs.</p></li>
<li><p><strong>Relationship:</strong> It combines the Prior belief with the evidence provided by the Likelihood.</p></li>
</ul>
<p><strong>Example (continuing):</strong></p>
<ul class="simple">
<li><p>After running the marketing campaign and observing the actual sales data, what’s the updated probability that the campaign increased sales by more than 20%?</p></li>
<li><p>After flipping the coin 10 times and getting 7 heads, what’s your updated belief about the coin being fair?</p></li>
</ul>
</section>
</section>
<section id="applications">
<h2>2. Applications<a class="headerlink" href="#applications" title="Link to this heading">#</a></h2>
</section>
<section id="bayes-rule-in-inference">
<h2>2.1. Bayes’ Rule in Inference<a class="headerlink" href="#bayes-rule-in-inference" title="Link to this heading">#</a></h2>
<p>Bayes’ Rule is the mathematical formula that connects the Prior, Likelihood, and Posterior probabilities:</p>
<div class="math notranslate nohighlight">
\[P(H|E) = \frac{P(E|H) \cdot P(H)}{P(E)}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(H|E)\)</span> is the Posterior probability: the probability of the hypothesis given the evidence.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(E|H)\)</span> is the Likelihood: the probability of the evidence given the hypothesis.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(H)\)</span> is the Prior probability: the probability of the hypothesis before seeing the evidence.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(E)\)</span> is the Marginal Likelihood (or Evidence): the total probability of the evidence. It acts as a normalizing constant to ensure the posterior probabilities sum to 1.</p></li>
</ul>
<p>The Marginal Likelihood <span class="math notranslate nohighlight">\(P(E)\)</span> can be calculated by summing (for discrete hypotheses) or integrating (for continuous hypotheses) the product of the likelihood and prior over all possible hypotheses:</p>
<p><span class="math notranslate nohighlight">\(P(E) = \sum P(E|H_i) \cdot P(H_i)\)</span></p>
<p>or</p>
<p><span class="math notranslate nohighlight">\(P(E) = \int P(E|H) \cdot P(H) \, dH\)</span></p>
<p><strong>Intuitive Interpretation:</strong></p>
<p>Posterior <span class="math notranslate nohighlight">\(\propto\)</span> Likelihood <span class="math notranslate nohighlight">\(\times\)</span> Prior</p>
<p>This means “Our updated belief is proportional to how well the evidence supports the hypothesis, weighted by our initial belief in the hypothesis.”</p>
<hr class="docutils" />
<section id="example-problem-statement-medical-diagnosis">
<h3><strong>Example Problem Statement (Medical Diagnosis):</strong><a class="headerlink" href="#example-problem-statement-medical-diagnosis" title="Link to this heading">#</a></h3>
<p>A rare disease affects 1% of the population. A new diagnostic test has been developed for this disease.</p>
<ul class="simple">
<li><p>The test has a <strong>sensitivity</strong> of 95%: If a person has the disease, the test will be positive 95% of the time (<span class="math notranslate nohighlight">\(P(\text{Positive}|\text{Disease}) = 0.95\)</span>).</p></li>
<li><p>The test has a <strong>specificity</strong> of 90%: If a person does NOT have the disease, the test will be negative 90% of the time (<span class="math notranslate nohighlight">\(P(\text{Negative}|\text{No Disease}) = 0.90\)</span>). This also means <span class="math notranslate nohighlight">\(P(\text{Positive}|\text{No Disease}) = 1 - 0.90 = 0.10\)</span>.</p></li>
</ul>
<p>You take the test, and it comes back <strong>positive</strong>. What is the probability that you actually have the disease?</p>
<p><strong>Let’s define our terms:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(H\)</span>: You have the disease (<span class="math notranslate nohighlight">\(D\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(\neg H\)</span>: You do not have the disease (<span class="math notranslate nohighlight">\(\neg D\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(E\)</span>: Test is Positive (<span class="math notranslate nohighlight">\(P\)</span>)</p></li>
</ul>
<p><strong>Known Probabilities:</strong></p>
<ul class="simple">
<li><p><strong>Prior <span class="math notranslate nohighlight">\(P(D)\)</span>:</strong> <span class="math notranslate nohighlight">\(P(D) = 0.01\)</span> (1% of the population has the disease)</p></li>
<li><p><strong>Prior <span class="math notranslate nohighlight">\(P(\neg D)\)</span>:</strong> <span class="math notranslate nohighlight">\(P(\neg D) = 1 - P(D) = 1 - 0.01 = 0.99\)</span></p></li>
<li><p><strong>Likelihood <span class="math notranslate nohighlight">\(P(P|D)\)</span>:</strong> <span class="math notranslate nohighlight">\(P(P|D) = 0.95\)</span> (Sensitivity)</p></li>
<li><p><strong>Likelihood <span class="math notranslate nohighlight">\(P(P|\neg D)\)</span>:</strong> <span class="math notranslate nohighlight">\(P(P|\neg D) = 1 - P(\text{Negative}|\neg D) = 1 - 0.90 = 0.10\)</span> (False Positive Rate)</p></li>
</ul>
<p><strong>We want to find the Posterior <span class="math notranslate nohighlight">\(P(D|P)\)</span>.</strong></p>
<p><strong>Manual Calculation:</strong></p>
<ol class="arabic simple">
<li><p><strong>Calculate the Marginal Likelihood <span class="math notranslate nohighlight">\(P(P)\)</span> (Probability of a Positive Test):</strong>
This accounts for both scenarios: testing positive when you have the disease, and testing positive when you don’t have the disease (false positive).
<span class="math notranslate nohighlight">\(P(P) = P(P|D) \cdot P(D) + P(P|\neg D) \cdot P(\neg D)\)</span>
<span class="math notranslate nohighlight">\(P(P) = (0.95 \times 0.01) + (0.10 \times 0.99)\)</span>
<span class="math notranslate nohighlight">\(P(P) = 0.0095 + 0.099\)</span>
<span class="math notranslate nohighlight">\(P(P) = 0.1085\)</span></p></li>
<li><p><strong>Apply Bayes’ Rule:</strong>
<span class="math notranslate nohighlight">\(P(D|P) = \frac{P(P|D) \cdot P(D)}{P(P)}\)</span>
<span class="math notranslate nohighlight">\(P(D|P) = \frac{0.95 \times 0.01}{0.1085}\)</span>
<span class="math notranslate nohighlight">\(P(D|P) = \frac{0.0095}{0.1085}\)</span>
<span class="math notranslate nohighlight">\(P(D|P) \approx 0.0875\)</span></p></li>
</ol>
<p><strong>Interpretation:</strong>
Even though the test is positive and seems quite accurate, the probability that you actually have the disease is only about <strong>8.75%</strong>. This seemingly counter-intuitive result highlights the importance of the <strong>prior probability</strong> for rare events. Because the disease is so rare, a positive test is still more likely to be a false positive than a true positive.</p>
</section>
</section>
<hr class="docutils" />
<section id="a-b-testing-bayesian-approach">
<h2>2.2. A/B Testing (Bayesian Approach)<a class="headerlink" href="#a-b-testing-bayesian-approach" title="Link to this heading">#</a></h2>
<p>A/B testing is a method of comparing two versions of a product, feature, or marketing campaign (A and B) to see which one performs better. In a Bayesian A/B test, instead of just looking for statistical significance (like p-values), we model the probability distribution of the conversion rates (or other metrics) for A and B, and then calculate the probability that B is better than A.</p>
<p><strong>Traditional (Frequentist) A/B Testing Issues:</strong></p>
<ul class="simple">
<li><p>Often focuses on fixed sample sizes and stopping rules.</p></li>
<li><p>P-values can be misinterpreted.</p></li>
<li><p>Doesn’t directly answer “What is the probability that B is better than A?”.</p></li>
</ul>
<p><strong>Bayesian A/B Testing Advantages:</strong></p>
<ul class="simple">
<li><p>More intuitive results (e.g., “There’s a 95% chance B is better than A”).</p></li>
<li><p>Can be continuously monitored, allowing for early stopping when there’s enough evidence.</p></li>
<li><p>Directly incorporates prior knowledge.</p></li>
</ul>
<section id="example-problem-statement-website-conversion">
<h3><strong>Example Problem Statement (Website Conversion):</strong><a class="headerlink" href="#example-problem-statement-website-conversion" title="Link to this heading">#</a></h3>
<p>A website wants to test two versions of a landing page:</p>
<ul class="simple">
<li><p><strong>Version A (Control):</strong> Currently used.</p></li>
<li><p><strong>Version B (New Design):</strong> Proposed.</p></li>
</ul>
<p>Historical data suggests Version A has a conversion rate of about 10%. We want to see if Version B is better. We run an experiment where:</p>
<ul class="simple">
<li><p>Version A is shown to 100 visitors, resulting in 10 conversions.</p></li>
<li><p>Version B is shown to 100 visitors, resulting in 12 conversions.</p></li>
</ul>
<p><strong>Goal:</strong> Estimate the conversion rates for A and B, and determine the probability that Version B has a higher conversion rate than Version A.</p>
<p><strong>Bayesian Approach (using Beta-Binomial Conjugate Prior):</strong></p>
<p>For binary outcomes (like conversion: yes/no), the Beta distribution is a common choice for the prior on the conversion rate (probability of success), because it’s a <strong>conjugate prior</strong> to the Binomial likelihood. This means the posterior will also be a Beta distribution, simplifying calculations.</p>
<ul class="simple">
<li><p>A Beta distribution is parameterized by two positive shape parameters, <span class="math notranslate nohighlight">\(\alpha\)</span> (alpha) and <span class="math notranslate nohighlight">\(\beta\)</span> (beta).</p></li>
<li><p>Mean of Beta(<span class="math notranslate nohighlight">\(\alpha, \beta\)</span>) is <span class="math notranslate nohighlight">\(\frac{\alpha}{\alpha + \beta}\)</span>.</p></li>
</ul>
<p><strong>Let’s define our Priors:</strong></p>
<ul class="simple">
<li><p><strong>Prior for Version A:</strong> Based on historical data, let’s set a slightly informative prior. If we believe the rate is around 10% (0.1) and we have some confidence (e.g., equivalent to 9 successes and 81 failures, totaling 90 observations, which gives 0.1), we could use Beta(10, 90). Or, for a more general weak prior that reflects uncertainty around 10%, we could use Beta(1, 9) which implies a prior belief that it’s around 10% but with high uncertainty, or even Beta(1,1) for an uninformative uniform prior. Let’s use a slightly more informative prior for A that reflects its historical performance: <strong>Beta(10, 90)</strong>. (This prior has a mean of 10/(10+90) = 0.1).</p></li>
<li><p><strong>Prior for Version B:</strong> Since it’s a new design, we might use a less informative prior, perhaps <strong>Beta(1, 9)</strong> (mean 0.1, but less certainty) or even <strong>Beta(1, 1)</strong> (uniform, all probabilities equally likely initially). Let’s use <strong>Beta(1, 9)</strong> to give it a slight lean towards 10% but still allow the data to dominate.</p></li>
</ul>
<p><strong>Applying the Likelihood (observing data):</strong></p>
<p>When we observe data (conversions and non-conversions), we update the Beta distribution’s parameters:</p>
<ul class="simple">
<li><p>If you had <span class="math notranslate nohighlight">\(\alpha_{prior}\)</span> successes and <span class="math notranslate nohighlight">\(\beta_{prior}\)</span> failures (or <span class="math notranslate nohighlight">\(\alpha_{prior}\)</span> and <span class="math notranslate nohighlight">\(\beta_{prior}\)</span> are the parameters), and you observe <span class="math notranslate nohighlight">\(k\)</span> successes and <span class="math notranslate nohighlight">\(n-k\)</span> failures in your experiment:</p></li>
<li><p>The <strong>Posterior</strong> parameters become: <span class="math notranslate nohighlight">\(\alpha_{posterior} = \alpha_{prior} + k\)</span> and <span class="math notranslate nohighlight">\(\beta_{posterior} = \beta_{prior} + (n-k)\)</span>.</p></li>
</ul>
<p><strong>Manual Calculation (Conceptual for parameters, Simulation for Comparison):</strong></p>
<ol class="arabic simple">
<li><p><strong>For Version A (Control):</strong></p>
<ul class="simple">
<li><p>Prior: Beta(<span class="math notranslate nohighlight">\(\alpha_A=10, \beta_A=90\)</span>)</p></li>
<li><p>Observed: <span class="math notranslate nohighlight">\(k_A=10\)</span> conversions, <span class="math notranslate nohighlight">\(n_A=100\)</span> visitors. So, <span class="math notranslate nohighlight">\(n_A-k_A = 90\)</span> failures.</p></li>
<li><p><strong>Posterior A:</strong> Beta(<span class="math notranslate nohighlight">\(10+10, 90+90\)</span>) = <strong>Beta(20, 180)</strong></p></li>
<li><p>Mean Posterior A: <span class="math notranslate nohighlight">\(20 / (20 + 180) = 20 / 200 = 0.10\)</span></p></li>
</ul>
</li>
<li><p><strong>For Version B (New Design):</strong></p>
<ul class="simple">
<li><p>Prior: Beta(<span class="math notranslate nohighlight">\(\alpha_B=1, \beta_B=9\)</span>)</p></li>
<li><p>Observed: <span class="math notranslate nohighlight">\(k_B=12\)</span> conversions, <span class="math notranslate nohighlight">\(n_B=100\)</span> visitors. So, <span class="math notranslate nohighlight">\(n_B-k_B = 88\)</span> failures.</p></li>
<li><p><strong>Posterior B:</strong> Beta(<span class="math notranslate nohighlight">\(1+12, 9+88\)</span>) = <strong>Beta(13, 97)</strong></p></li>
<li><p>Mean Posterior B: <span class="math notranslate nohighlight">\(13 / (13 + 97) = 13 / 110 \approx 0.118\)</span></p></li>
</ul>
</li>
</ol>
<p><strong>Plotting the Posterior Distributions:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">beta</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="c1"># Set a style for better aesthetics</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
<span class="c1"># plt.rcParams[&#39;font.family&#39;] = &#39;Inter&#39; # Set font to Inter</span>

<span class="c1"># --- Bayesian A/B Test Example ---</span>

<span class="c1"># Posterior parameters for A and B</span>
<span class="n">alpha_A_posterior</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">beta_A_posterior</span> <span class="o">=</span> <span class="mi">180</span>

<span class="n">alpha_B_posterior</span> <span class="o">=</span> <span class="mi">13</span>
<span class="n">beta_B_posterior</span> <span class="o">=</span> <span class="mi">97</span>

<span class="c1"># Create a range of possible conversion rates (x-axis)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span> <span class="c1"># From 0% to 25% conversion rate</span>

<span class="c1"># Calculate the PDF for each posterior distribution</span>
<span class="n">pdf_A</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha_A_posterior</span><span class="p">,</span> <span class="n">beta_A_posterior</span><span class="p">)</span>
<span class="n">pdf_B</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha_B_posterior</span><span class="p">,</span> <span class="n">beta_B_posterior</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf_A</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Posterior A (Beta(</span><span class="si">{</span><span class="n">alpha_A_posterior</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">beta_A_posterior</span><span class="si">}</span><span class="s1">))&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf_B</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Posterior B (Beta(</span><span class="si">{</span><span class="n">alpha_B_posterior</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">beta_B_posterior</span><span class="si">}</span><span class="s1">))&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightcoral&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Posterior Distributions of Conversion Rates for A and B&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Conversion Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability Density&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">alpha_A_posterior</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha_A_posterior</span> <span class="o">+</span> <span class="n">beta_A_posterior</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Mean A: </span><span class="si">{</span><span class="n">alpha_A_posterior</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">alpha_A_posterior</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta_A_posterior</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">alpha_B_posterior</span> <span class="o">/</span> <span class="p">(</span><span class="n">alpha_B_posterior</span> <span class="o">+</span> <span class="n">beta_B_posterior</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightcoral&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Mean B: </span><span class="si">{</span><span class="n">alpha_B_posterior</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">alpha_B_posterior</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta_B_posterior</span><span class="p">)</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># --- Manual Calculation (Simulation for P(B &gt; A)) ---</span>
<span class="c1"># This step is typically done via simulation due to complex integration</span>
<span class="n">num_simulations</span> <span class="o">=</span> <span class="mi">100000</span>

<span class="c1"># Sample from the posterior distributions</span>
<span class="n">samples_A</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">alpha_A_posterior</span><span class="p">,</span> <span class="n">beta_A_posterior</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_simulations</span><span class="p">)</span>
<span class="n">samples_B</span> <span class="o">=</span> <span class="n">beta</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">alpha_B_posterior</span><span class="p">,</span> <span class="n">beta_B_posterior</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_simulations</span><span class="p">)</span>

<span class="c1"># Calculate the probability that B is greater than A</span>
<span class="n">prob_B_greater_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">samples_B</span> <span class="o">&gt;</span> <span class="n">samples_A</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean Posterior Conversion Rate for A: </span><span class="si">{</span><span class="n">alpha_A_posterior</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">alpha_A_posterior</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta_A_posterior</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean Posterior Conversion Rate for B: </span><span class="si">{</span><span class="n">alpha_B_posterior</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">alpha_B_posterior</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">beta_B_posterior</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Probability that Version B is better than Version A: </span><span class="si">{</span><span class="n">prob_B_greater_A</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/5f24c886032557d9eaf6c20290ac00accacf64b94d7a419242cd645750bf0e42.png" src="../../_images/5f24c886032557d9eaf6c20290ac00accacf64b94d7a419242cd645750bf0e42.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean Posterior Conversion Rate for A: 0.100
Mean Posterior Conversion Rate for B: 0.118
Probability that Version B is better than Version A: 68.26%
</pre></div>
</div>
</div>
</div>
<p><strong>Interpretation of the A/B Test Plot and Simulation:</strong></p>
<ul class="simple">
<li><p>The plot shows two distinct probability distributions for the conversion rates of A and B. Version B’s distribution is slightly shifted to the right, indicating a higher probable conversion rate.</p></li>
<li><p>The overlap of the distributions signifies the uncertainty.</p></li>
<li><p>The simulation estimates the probability that a random sample from B’s posterior is greater than a random sample from A’s posterior. A value of, say, 80% means there’s an 80% chance that B’s true conversion rate is higher than A’s. This is a much more direct and actionable insight for business decision-making than a p-value.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="decision-making-under-uncertainty">
<h2>2.3. Decision Making Under Uncertainty<a class="headerlink" href="#decision-making-under-uncertainty" title="Link to this heading">#</a></h2>
<p>Bayesian inference is a powerful tool for making optimal decisions when faced with uncertainty. It allows us to systematically combine prior beliefs, observed data, and the costs/benefits of different outcomes.</p>
<p><strong>Key Components:</strong></p>
<ol class="arabic simple">
<li><p><strong>Possible Actions:</strong> The choices you can make.</p></li>
<li><p><strong>Possible States of Nature:</strong> The uncertain outcomes that affect the success of your actions.</p></li>
<li><p><strong>Prior Probabilities:</strong> Your initial beliefs about the states of nature.</p></li>
<li><p><strong>Likelihoods:</strong> How likely your observations are given each state of nature.</p></li>
<li><p><strong>Posterior Probabilities:</strong> Updated beliefs about the states of nature after observations.</p></li>
<li><p><strong>Utilities/Losses:</strong> The value (or cost) associated with each combination of action and state of nature.</p></li>
<li><p><strong>Expected Utility/Loss:</strong> The average utility/loss for each action, weighted by the posterior probabilities of the states of nature.</p></li>
</ol>
<p><strong>Decision Rule:</strong> Choose the action that maximizes expected utility or minimizes expected loss.</p>
<section id="example-problem-statement-investment-decision">
<h3><strong>Example Problem Statement (Investment Decision):</strong><a class="headerlink" href="#example-problem-statement-investment-decision" title="Link to this heading">#</a></h3>
<p>You are a venture capitalist considering investing $1 Million in a startup.</p>
<ul class="simple">
<li><p><strong>Action 1:</strong> Invest ($I)</p></li>
<li><p><strong>Action 2:</strong> Don’t Invest (<span class="math notranslate nohighlight">\(\\neg I\)</span>)</p></li>
</ul>
<p>There are two possible states of nature for the startup:</p>
<ul class="simple">
<li><p><strong>State 1:</strong> Startup succeeds (<span class="math notranslate nohighlight">\(S\)</span>)</p></li>
<li><p><strong>State 2:</strong> Startup fails (<span class="math notranslate nohighlight">\(\\neg S\)</span>)</p></li>
</ul>
<p><strong>Prior Beliefs:</strong></p>
<ul class="simple">
<li><p>You initially believe there’s a <strong>15% chance the startup succeeds</strong> (<span class="math notranslate nohighlight">\(P(S) = 0.15\)</span>).</p></li>
<li><p>So, <span class="math notranslate nohighlight">\(P(\\neg S) = 0.85\)</span>.</p></li>
</ul>
<p><strong>Utilities (Profit/Loss in $ Millions):</strong></p>
<ul class="simple">
<li><p>If you Invest and Startup Succeeds (<span class="math notranslate nohighlight">\(I, S\)</span>): Profit of <span class="math notranslate nohighlight">\(5 Million (Net: \)</span>4M, after $1M investment)</p></li>
<li><p>If you Invest and Startup Fails (<span class="math notranslate nohighlight">\(I, \\neg S\)</span>): Loss of $1 Million</p></li>
<li><p>If you Don’t Invest (regardless of success): Profit of $0 Million</p></li>
</ul>
<p><strong>New Evidence (E):</strong>
You hire a consultant to evaluate the startup. The consultant gives a “Positive” review (<span class="math notranslate nohighlight">\(R+\)</span>).</p>
<ul class="simple">
<li><p><strong>Consultant’s accuracy (Likelihoods):</strong></p>
<ul>
<li><p>If the startup truly succeeds, the consultant gives a Positive review 80% of the time: <span class="math notranslate nohighlight">\(P(R+|S) = 0.80\)</span></p></li>
<li><p>If the startup truly fails, the consultant gives a Positive review only 10% of the time: <span class="math notranslate nohighlight">\(P(R+|\\neg S) = 0.10\)</span></p></li>
</ul>
</li>
</ul>
<p><strong>Goal:</strong> Based on the consultant’s positive review, should you invest?</p>
<p><strong>Manual Calculation:</strong></p>
<ol class="arabic">
<li><p><strong>Calculate Posterior Probabilities of States of Nature given <span class="math notranslate nohighlight">\(R+\)</span>:</strong></p>
<ul class="simple">
<li><p><strong>Marginal Likelihood <span class="math notranslate nohighlight">\(P(R+)\)</span>:</strong>
<span class="math notranslate nohighlight">\(P(R+) = P(R+|S) \\cdot P(S) + P(R+|\\neg S) \\cdot P(\\neg S)\)</span>
<span class="math notranslate nohighlight">\(P(R+) = (0.80 \\times 0.15) + (0.10 \\times 0.85)\)</span>
<span class="math notranslate nohighlight">\(P(R+) = 0.12 + 0.085\)</span>
<span class="math notranslate nohighlight">\(P(R+) = 0.205\)</span></p></li>
<li><p><strong>Posterior <span class="math notranslate nohighlight">\(P(S|R+)\)</span>:</strong>
<span class="math notranslate nohighlight">\(P(S|R+) = \\frac{P(R+|S) \\cdot P(S)}{P(R+)}\)</span>
<span class="math notranslate nohighlight">\(P(S|R+) = \\frac{0.80 \\times 0.15}{0.205} = \\frac{0.12}{0.205} \\approx 0.585\)</span></p></li>
<li><p><strong>Posterior <span class="math notranslate nohighlight">\(P(\\neg S|R+)\)</span>:</strong>
<span class="math notranslate nohighlight">\(P(\\neg S|R+) = \\frac{P(R+|\\neg S) \\cdot P(\\neg S)}{P(R+)}\)</span>
<span class="math notranslate nohighlight">\(P(\\neg S|R+) = \\frac{0.10 \\times 0.85}{0.205} = \\frac{0.085}{0.205} \\approx 0.415\)</span>
(Check: <span class="math notranslate nohighlight">\(0.585 + 0.415 = 1.0\)</span>)</p></li>
</ul>
<p><strong>Interpretation of Posteriors:</strong> A positive review significantly increased your belief in the startup’s success, from a prior of 15% to a posterior of almost 58.5%.</p>
</li>
<li><p><strong>Calculate Expected Utility for Each Action (using Posterior Probabilities):</strong></p>
<ul class="simple">
<li><p><strong>Expected Utility of “Invest” (<span class="math notranslate nohighlight">\(EU(I)\)</span>):</strong>
<span class="math notranslate nohighlight">\(EU(I) = ( \\text{Utility}(I,S) \\times P(S|R+) ) + ( \\text{Utility}(I, \\neg S) \\times P(\\neg S|R+) )\)</span>
<span class="math notranslate nohighlight">\(EU(I) = (4 \\times 0.585) + (-1 \\times 0.415)\)</span>
<span class="math notranslate nohighlight">\(EU(I) = 2.34 - 0.415\)</span>
<span class="math notranslate nohighlight">\(EU(I) = 1.925\)</span> Million</p></li>
<li><p><strong>Expected Utility of “Don’t Invest” (<span class="math notranslate nohighlight">\(EU(\\neg I)\)</span>):</strong>
<span class="math notranslate nohighlight">\(EU(\\neg I) = ( \\text{Utility}(\\neg I,S) \\times P(S|R+) ) + ( \\text{Utility}(\\neg I, \\neg S) \\times P(\\neg S|R+) )\)</span>
<span class="math notranslate nohighlight">\(EU(\\neg I) = (0 \\times 0.585) + (0 \\times 0.415)\)</span>
<span class="math notranslate nohighlight">\(EU(\\neg I) = 0\)</span> Million</p></li>
</ul>
</li>
</ol>
<p><strong>Decision:</strong></p>
<p>Since <span class="math notranslate nohighlight">\(EU(I) = 1.925\)</span> Million is greater than <span class="math notranslate nohighlight">\(EU(\\neg I) = 0\)</span> Million, the optimal decision, based on the Bayesian analysis, is to <strong>Invest</strong> in the startup.</p>
</section>
</section>
<hr class="docutils" />
<section id="visualizing-decision-making-conceptual-plot">
<h2><strong>Visualizing Decision Making (Conceptual Plot):</strong><a class="headerlink" href="#visualizing-decision-making-conceptual-plot" title="Link to this heading">#</a></h2>
<p>While a direct plot for decision-making under uncertainty isn’t a single standard chart like a scatter plot, we can conceptually visualize the shift in probabilities and expected utilities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
<span class="c1"># plt.rcParams[&#39;font.family&#39;] = &#39;Inter&#39; # Set font to Inter</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Conceptual Visualization for Decision Making Under Uncertainty ---&quot;</span><span class="p">)</span>

<span class="c1"># Data from the Investment Decision example</span>
<span class="n">prior_S</span> <span class="o">=</span> <span class="mf">0.15</span>
<span class="n">prior_not_S</span> <span class="o">=</span> <span class="mf">0.85</span>
<span class="n">posterior_S</span> <span class="o">=</span> <span class="mf">0.585</span>
<span class="n">posterior_not_S</span> <span class="o">=</span> <span class="mf">0.415</span>

<span class="c1"># Create labels for plotting</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Startup Succeeds (S)&#39;</span><span class="p">,</span> <span class="s1">&#39;Startup Fails (~S)&#39;</span><span class="p">]</span>
<span class="n">prior_probs</span> <span class="o">=</span> <span class="p">[</span><span class="n">prior_S</span><span class="p">,</span> <span class="n">prior_not_S</span><span class="p">]</span>
<span class="n">posterior_probs</span> <span class="o">=</span> <span class="p">[</span><span class="n">posterior_S</span><span class="p">,</span> <span class="n">posterior_not_S</span><span class="p">]</span>

<span class="c1"># Plotting Prior vs. Posterior Probabilities</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Prior Plot</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">prior_probs</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="s1">&#39;lightcoral&#39;</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Prior Probabilities of Startup States&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Probability&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">prior_probs</span><span class="p">):</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="o">+</span> <span class="mf">0.02</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s1">.1%</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Posterior Plot</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">posterior_probs</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="s1">&#39;lightcoral&#39;</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Posterior Probabilities of Startup States (After Positive Review)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">posterior_probs</span><span class="p">):</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="o">+</span> <span class="mf">0.02</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">v</span><span class="si">:</span><span class="s1">.1%</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Shift in Beliefs: Prior vs. Posterior Probabilities&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.02</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">rect</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.96</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plotting Expected Utility</span>
<span class="n">actions</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Invest&#39;</span><span class="p">,</span> <span class="s2">&quot;Don&#39;t Invest&quot;</span><span class="p">]</span>
<span class="n">expected_utilities</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.925</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># In Millions</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">bars</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">expected_utilities</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;mediumseagreen&#39;</span><span class="p">,</span> <span class="s1">&#39;grey&#39;</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Expected Utility for Each Investment Action&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Action&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Expected Utility ($ Million)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">expected_utilities</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">expected_utilities</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="k">for</span> <span class="n">bar</span> <span class="ow">in</span> <span class="n">bars</span><span class="p">:</span>
    <span class="n">yval</span> <span class="o">=</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">bar</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">yval</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">yval</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Conceptual Visualization for Decision Making Under Uncertainty ---
</pre></div>
</div>
<img alt="../../_images/e262c16b28bfdeea4abd854dc1dc6e9aa9b8a0f4302c45ad7f5b80153e51f9e0.png" src="../../_images/e262c16b28bfdeea4abd854dc1dc6e9aa9b8a0f4302c45ad7f5b80153e51f9e0.png" />
<img alt="../../_images/0e42a8acdab3636b75d60e6b9279b9a2c8832bcc404baa9f6e664ca6320a6b44.png" src="../../_images/0e42a8acdab3636b75d60e6b9279b9a2c8832bcc404baa9f6e664ca6320a6b44.png" />
</div>
</div>
<p><strong>Interpretation of Decision Making Plots:</strong></p>
<ul class="simple">
<li><p><strong>Prior vs. Posterior Probabilities Plot:</strong> This side-by-side bar chart clearly visualizes how the consultant’s positive review dramatically shifted your belief about the startup’s success. The probability of success jumps from 15% (prior) to 58.5% (posterior).</p></li>
<li><p><strong>Expected Utility Plot:</strong> This bar chart directly compares the expected financial outcome (utility) of each action. It clearly shows that “Invest” has a positive expected utility, while “Don’t Invest” has an expected utility of zero, making “Invest” the rational choice given the updated probabilities and defined utilities.</p></li>
</ul>
<p>These visualizations help communicate the rationale behind Bayesian decision-making, showing both the updated beliefs and the financial implications of each choice.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="a-b-testing-metrics-and-methodologies">
<h1>A/B Testing Metrics and Methodologies<a class="headerlink" href="#a-b-testing-metrics-and-methodologies" title="Link to this heading">#</a></h1>
<p>This section delves into key metrics used in A/B testing and explores two common testing methodologies: Fixed Horizon vs. Sequential Testing.</p>
<section id="lift-p-values-conversion-rates">
<h2>1. Lift, p-values, Conversion Rates<a class="headerlink" href="#lift-p-values-conversion-rates" title="Link to this heading">#</a></h2>
<p>These are fundamental concepts for understanding and evaluating the results of A/B tests.</p>
<section id="conversion-rate">
<h3>1.1. Conversion Rate<a class="headerlink" href="#conversion-rate" title="Link to this heading">#</a></h3>
<p><strong>Explanation:</strong>
The <strong>Conversion Rate</strong> is the percentage of visitors or users who complete a desired action (a “conversion”) out of the total number of visitors or users. It’s a core metric in A/B testing, as the goal of most tests is to increase this rate.</p>
<p><strong>Formula:</strong>
$<span class="math notranslate nohighlight">\(\text{Conversion Rate} = \frac{\text{Number of Conversions}}{\text{Total Number of Visitors/Users}} \times 100\%\)</span>$</p>
<p><strong>Example:</strong> If 100 people visit a page and 5 make a purchase, the conversion rate is 5%.</p>
</section>
<section id="lift-relative-increase">
<h3>1.2. Lift (Relative Increase)<a class="headerlink" href="#lift-relative-increase" title="Link to this heading">#</a></h3>
<p><strong>Explanation:</strong>
<strong>Lift</strong> (also known as relative lift or relative increase) measures the percentage improvement (or decrease) of a variant’s performance compared to the control group. It quantifies the <em>magnitude</em> of the change.</p>
<p><strong>Formula:</strong>
$<span class="math notranslate nohighlight">\(\text{Lift} = \frac{\text{Variant Conversion Rate} - \text{Control Conversion Rate}}{\text{Control Conversion Rate}} \times 100\%\)</span>$</p>
<p><strong>Example:</strong> If Control has a 5% conversion rate and Variant has a 6% conversion rate:
Lift = ((6% - 5%) / 5%) * 100% = (1% / 5%) * 100% = 20%. This means the Variant achieved a 20% lift in conversion rate.</p>
</section>
<section id="p-value">
<h3>1.3. p-value<a class="headerlink" href="#p-value" title="Link to this heading">#</a></h3>
<p><strong>Explanation:</strong>
In the context of A/B testing (particularly frequentist A/B testing), the <strong>p-value</strong> helps determine the statistical significance of the observed difference between the control and variant. It is the probability of observing a difference as extreme as, or more extreme than, the one measured in your experiment, <em>assuming that there is no true difference between the two versions (i.e., the null hypothesis is true)</em>.</p>
<ul class="simple">
<li><p><strong>Small p-value (typically <span class="math notranslate nohighlight">\(\le \alpha\)</span>, e.g., 0.05):</strong> Suggests that the observed difference is unlikely to have occurred by random chance alone. This provides evidence to <strong>reject the null hypothesis</strong> and conclude that the variant is statistically significantly different from the control.</p></li>
<li><p><strong>Large p-value (typically <span class="math notranslate nohighlight">\(&gt; \alpha\)</span>):</strong> Suggests that the observed difference could easily have occurred by random chance. This means there is <strong>not enough evidence to reject the null hypothesis</strong>, and you cannot conclude a statistically significant difference.</p></li>
</ul>
<p><strong>Important Note:</strong> A p-value does <em>not</em> tell you the probability that the null hypothesis is true, nor does it tell you the magnitude or practical importance of the difference. It only speaks to the statistical evidence against the null hypothesis.</p>
<hr class="docutils" />
<section id="problem-statement-manual-calculation-conversion-rate-lift">
<h4><strong>Problem Statement &amp; Manual Calculation (Conversion Rate &amp; Lift):</strong><a class="headerlink" href="#problem-statement-manual-calculation-conversion-rate-lift" title="Link to this heading">#</a></h4>
<p>An e-commerce company ran an A/B test on their product page button color.</p>
<ul class="simple">
<li><p><strong>Control (Original Green Button):</strong></p>
<ul>
<li><p>Visitors: 1000</p></li>
<li><p>Conversions (Clicks): 50</p></li>
</ul>
</li>
<li><p><strong>Variant (New Red Button):</strong></p>
<ul>
<li><p>Visitors: 1000</p></li>
<li><p>Conversions (Clicks): 65</p></li>
</ul>
</li>
</ul>
<p>Calculate the conversion rates for Control and Variant, and the Lift of the Variant over the Control.</p>
<p><strong>Manual Calculation:</strong></p>
<ol class="arabic simple">
<li><p><strong>Control Conversion Rate:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(CR_{\text{Control}} = (50 / 1000) \times 100\% = 0.05 \times 100\% = \mathbf{5.0\%}\)</span></p></li>
</ul>
</li>
<li><p><strong>Variant Conversion Rate:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(CR_{\text{Variant}} = (65 / 1000) \times 100\% = 0.065 \times 100\% = \mathbf{6.5\%}\)</span></p></li>
</ul>
</li>
<li><p><strong>Lift:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\text{Lift} = ((CR_{\text{Variant}} - CR_{\text{Control}}) / CR_{\text{Control}}) \times 100\%\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Lift} = ((0.065 - 0.050) / 0.050) \times 100\%\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Lift} = (0.015 / 0.050) \times 100\%\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\text{Lift} = 0.30 \times 100\% = \mathbf{30.0\%}\)</span></p></li>
</ul>
</li>
</ol>
<p><strong>Interpretation:</strong> The new red button resulted in a 30% lift in conversion rate compared to the original green button.</p>
<p><em>(Note: Calculating the p-value manually for A/B tests (e.g., using a Z-test for proportions) is more involved and typically done by software. It would involve calculating a test statistic and then looking up its probability in a standard normal distribution table.)</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.stats.proportion</span><span class="w"> </span><span class="kn">import</span> <span class="n">proportions_ztest</span> <span class="c1"># For p-value calculation</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.sans-serif&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DejaVu Sans&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- A/B Testing Metrics: Conversion Rate, Lift, p-value ---&quot;</span><span class="p">)</span>

<span class="c1"># Data from problem statement</span>
<span class="n">control_visitors</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">control_conversions</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">variant_visitors</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">variant_conversions</span> <span class="o">=</span> <span class="mi">65</span>
<span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="c1"># Significance level</span>

<span class="c1"># Calculate Conversion Rates</span>
<span class="n">cr_control</span> <span class="o">=</span> <span class="n">control_conversions</span> <span class="o">/</span> <span class="n">control_visitors</span>
<span class="n">cr_variant</span> <span class="o">=</span> <span class="n">variant_conversions</span> <span class="o">/</span> <span class="n">variant_visitors</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Control Conversion Rate: </span><span class="si">{</span><span class="n">cr_control</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Variant Conversion Rate: </span><span class="si">{</span><span class="n">cr_variant</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Calculate Lift</span>
<span class="n">lift</span> <span class="o">=</span> <span class="p">((</span><span class="n">cr_variant</span> <span class="o">-</span> <span class="n">cr_control</span><span class="p">)</span> <span class="o">/</span> <span class="n">cr_control</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Lift: </span><span class="si">{</span><span class="n">lift</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="c1"># Calculate p-value (using Z-test for proportions)</span>
<span class="c1"># Null Hypothesis: p_control = p_variant</span>
<span class="c1"># Alternative Hypothesis: p_control != p_variant (two-sided)</span>
<span class="n">conversions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">control_conversions</span><span class="p">,</span> <span class="n">variant_conversions</span><span class="p">])</span>
<span class="n">nobs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">control_visitors</span><span class="p">,</span> <span class="n">variant_visitors</span><span class="p">])</span>

<span class="n">z_stat</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="n">proportions_ztest</span><span class="p">(</span><span class="n">conversions</span><span class="p">,</span> <span class="n">nobs</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Z-statistic: </span><span class="si">{</span><span class="n">z_stat</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Decision based on p-value</span>
<span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;=</span> <span class="n">alpha</span><span class="p">:</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="s2">&quot;Reject Null Hypothesis (Statistically Significant)&quot;</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="s2">&quot;Fail to Reject Null Hypothesis (Not Statistically Significant)&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Decision (at alpha=</span><span class="si">{</span><span class="n">alpha</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">decision</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># --- Plotting Conversion Rates and Lift ---</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Control&#39;</span><span class="p">,</span> <span class="s1">&#39;Variant&#39;</span><span class="p">]</span>
<span class="n">conversion_rates</span> <span class="o">=</span> <span class="p">[</span><span class="n">cr_control</span><span class="p">,</span> <span class="n">cr_variant</span><span class="p">]</span>
<span class="n">lift_percentage</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">lift</span><span class="p">]</span> <span class="c1"># Lift for control is 0</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Plot Conversion Rates</span>
<span class="n">bars_cr</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">conversion_rates</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="s1">&#39;lightcoral&#39;</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Conversion Rates&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Conversion Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">conversion_rates</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">bar</span> <span class="ow">in</span> <span class="n">bars_cr</span><span class="p">:</span>
    <span class="n">yval</span> <span class="o">=</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">bar</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">yval</span> <span class="o">+</span> <span class="mf">0.002</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">yval</span><span class="si">:</span><span class="s1">.2%</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>

<span class="c1"># Plot Lift</span>
<span class="n">bars_lift</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">lift_percentage</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="s1">&#39;mediumseagreen&#39;</span><span class="p">],</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Lift (Relative Increase)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Lift (%)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">lift_percentage</span><span class="p">))</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">lift_percentage</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">bar</span> <span class="ow">in</span> <span class="n">bars_lift</span><span class="p">:</span>
    <span class="n">yval</span> <span class="o">=</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_height</span><span class="p">()</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">bar</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">yval</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">yval</span><span class="p">)</span> <span class="k">if</span> <span class="n">yval</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.01</span><span class="p">),</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">yval</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;A/B Test Results: Conversion Rates and Lift&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.02</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">rect</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- A/B Testing Metrics: Conversion Rate, Lift, p-value ---
Control Conversion Rate: 5.00%
Variant Conversion Rate: 6.50%
Lift: 30.00%

Z-statistic: -1.441
P-value: 0.150
Decision (at alpha=0.05): Fail to Reject Null Hypothesis (Not Statistically Significant)
</pre></div>
</div>
<img alt="../../_images/d562e8e4a562218a1996a5c062234ae83e80c7a301ede2a4f3947c35d679ad6d.png" src="../../_images/d562e8e4a562218a1996a5c062234ae83e80c7a301ede2a4f3947c35d679ad6d.png" />
</div>
</div>
</section>
</section>
</section>
<hr class="docutils" />
<section id="sequential-testing-vs-fixed-horizon-testing">
<h2>2. Sequential Testing vs. Fixed Horizon Testing<a class="headerlink" href="#sequential-testing-vs-fixed-horizon-testing" title="Link to this heading">#</a></h2>
<p>These are two different methodologies for deciding when to stop an A/B test and analyze its results.</p>
<section id="fixed-horizon-testing-traditional-a-b-testing">
<h3>2.1. Fixed Horizon Testing (Traditional A/B Testing)<a class="headerlink" href="#fixed-horizon-testing-traditional-a-b-testing" title="Link to this heading">#</a></h3>
<p><strong>Explanation:</strong>
In <strong>Fixed Horizon Testing</strong> (also known as fixed-sample-size testing), you decide on the sample size (number of visitors/users) and the duration of the experiment <em>before</em> the test begins. The test runs for this predetermined period or until the pre-calculated sample size is reached, and <em>only then</em> are the results analyzed for statistical significance.</p>
<p><strong>How it works:</strong></p>
<ol class="arabic simple">
<li><p><strong>Pre-calculation:</strong> You use a power analysis to calculate the minimum sample size needed to detect a certain effect size (e.g., a 10% lift) with a desired statistical power (e.g., 80%) and significance level (<span class="math notranslate nohighlight">\(\\alpha=0.05\)</span>).</p></li>
<li><p><strong>Run to Completion:</strong> The test runs until this exact sample size is collected for both the control and variant groups.</p></li>
<li><p><strong>Single Analysis:</strong> Results are analyzed <em>only once</em> at the end of the experiment.</p></li>
</ol>
<p><strong>Pros:</strong></p>
<ul class="simple">
<li><p><strong>Simplicity:</strong> Conceptually straightforward to set up and analyze.</p></li>
<li><p><strong>Statistical Validity (when done correctly):</strong> If the sample size is calculated correctly and no “peeking” occurs, the statistical properties (like Type I error rate) are maintained.</p></li>
</ul>
<p><strong>Cons:</strong></p>
<ul class="simple">
<li><p><strong>Inefficiency:</strong> Tests might run longer than necessary if a clear winner emerges early, or unnecessarily short if more data is needed.</p></li>
<li><p><strong>Ethical Concerns:</strong> If a variant is performing significantly worse, users might be exposed to a suboptimal experience for longer than necessary.</p></li>
<li><p><strong>“Peeking” Problem:</strong> If you frequently look at the results before the test is complete and stop early based on a “significant” result, it inflates the Type I error rate. This is a major statistical fallacy in fixed horizon testing.</p></li>
</ul>
<section id="conceptual-problem-statement-fixed-horizon">
<h4><strong>Conceptual Problem Statement (Fixed Horizon):</strong><a class="headerlink" href="#conceptual-problem-statement-fixed-horizon" title="Link to this heading">#</a></h4>
<p>A marketing team wants to test a new ad creative. They determine they need 20,000 impressions per variant to detect a 1% lift in click-through rate (CTR) with 80% power and <span class="math notranslate nohighlight">\(\\alpha=0.05\)</span>. They decide to run the test for exactly 2 weeks to gather these impressions. They will only check the results after 2 weeks.</p>
</section>
</section>
<section id="sequential-testing-continuous-monitoring">
<h3>2.2. Sequential Testing (Continuous Monitoring)<a class="headerlink" href="#sequential-testing-continuous-monitoring" title="Link to this heading">#</a></h3>
<p><strong>Explanation:</strong>
<strong>Sequential Testing</strong> (or continuous monitoring) allows you to analyze test results <em>multiple times</em> during the experiment and potentially stop the test early if there’s sufficient evidence for a winner (or a loser), or if it becomes clear that no significant difference will be found. This addresses the “peeking” problem of fixed horizon testing.</p>
<p><strong>How it works:</strong></p>
<ol class="arabic simple">
<li><p><strong>Pre-calculation (Optional but good practice):</strong> You might still estimate an initial sample size, but it’s not a strict stopping rule.</p></li>
<li><p><strong>Multiple Analyses:</strong> Results are analyzed at predefined intervals (e.g., daily, weekly, or after every X conversions).</p></li>
<li><p><strong>Adjusted Thresholds:</strong> To maintain the overall Type I error rate (<span class="math notranslate nohighlight">\(\\alpha\)</span>) across multiple checks, sequential testing uses <em>adjusted</em> significance thresholds. These thresholds are stricter at the beginning of the test and become looser as more data is collected. This prevents false positives from early, random fluctuations.</p></li>
<li><p><strong>Stopping Rules:</strong> The test stops when:</p>
<ul class="simple">
<li><p>A variant crosses the significance threshold (a winner is declared).</p></li>
<li><p>It becomes highly improbable that a significant difference will be found (futility stopping).</p></li>
<li><p>A maximum allowed sample size is reached.</p></li>
</ul>
</li>
</ol>
<p><strong>Pros:</strong></p>
<ul class="simple">
<li><p><strong>Efficiency:</strong> Can stop tests earlier, saving time and resources.</p></li>
<li><p><strong>Ethical:</strong> Minimizes exposure to suboptimal variants.</p></li>
<li><p><strong>Flexibility:</strong> Adapts to the data as it comes in.</p></li>
<li><p><strong>Statistical Validity:</strong> Properly designed sequential tests maintain the desired Type I error rate.</p></li>
</ul>
<p><strong>Cons:</strong></p>
<ul class="simple">
<li><p><strong>Complexity:</strong> Requires more complex statistical methods (e.g., using alpha spending functions like O’Brien-Fleming or Pocock boundaries) to adjust significance thresholds.</p></li>
<li><p><strong>Requires Specialized Tools:</strong> Often needs dedicated A/B testing platforms or statistical libraries that support sequential analysis.</p></li>
</ul>
<section id="conceptual-problem-statement-sequential-testing">
<h4><strong>Conceptual Problem Statement (Sequential Testing):</strong><a class="headerlink" href="#conceptual-problem-statement-sequential-testing" title="Link to this heading">#</a></h4>
<p>The same marketing team from the fixed horizon example decides to use sequential testing. They set up their test to check results daily, using an alpha spending function. On day 3, the new ad creative shows a very strong, statistically significant lift (crossing the adjusted threshold). The test is stopped, and the new creative is rolled out to 100% of traffic immediately.</p>
</section>
<hr class="docutils" />
<section id="conceptual-plot-fixed-horizon-vs-sequential-testing">
<h4><strong>Conceptual Plot: Fixed Horizon vs. Sequential Testing</strong><a class="headerlink" href="#conceptual-plot-fixed-horizon-vs-sequential-testing" title="Link to this heading">#</a></h4>
<p>This plot illustrates how the decision boundaries for statistical significance change over time in sequential testing compared to a fixed horizon test.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.sans-serif&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DejaVu Sans&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Conceptual Plot: Fixed Horizon vs. Sequential Testing ---&quot;</span><span class="p">)</span>

<span class="c1"># Simulate Z-scores over time for an A/B test</span>
<span class="c1"># Imagine a test where variant is truly better, but with noise</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">48</span><span class="p">)</span>
<span class="n">num_observations</span> <span class="o">=</span> <span class="mi">200</span> <span class="c1"># Max observations</span>
<span class="n">z_scores_simulated</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">num_observations</span><span class="p">))</span> <span class="c1"># Drift towards positive Z-score</span>

<span class="c1"># Fixed Horizon: Constant critical value (e.g., Z=1.96 for alpha=0.05 two-tailed)</span>
<span class="n">fixed_critical_value</span> <span class="o">=</span> <span class="mf">1.96</span>
<span class="n">fixed_horizon_line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">num_observations</span><span class="p">,</span> <span class="n">fixed_critical_value</span><span class="p">)</span>

<span class="c1"># Sequential Testing: Example of a simple decreasing boundary (conceptual, not exact O&#39;Brien-Fleming)</span>
<span class="c1"># In reality, these are more complex to calculate</span>
<span class="c1"># For illustrative purposes, let&#39;s make it start higher and decrease towards fixed_critical_value</span>
<span class="n">sequential_upper_boundary</span> <span class="o">=</span> <span class="n">fixed_critical_value</span> <span class="o">+</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_observations</span><span class="p">)</span> <span class="o">/</span> <span class="mi">50</span><span class="p">))</span>
<span class="n">sequential_lower_boundary</span> <span class="o">=</span> <span class="o">-</span><span class="n">sequential_upper_boundary</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z_scores_simulated</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Observed Z-score (Simulated)&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">fixed_critical_value</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Fixed Horizon Critical Value (Z=</span><span class="si">{</span><span class="n">fixed_critical_value</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="o">-</span><span class="n">fixed_critical_value</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sequential_upper_boundary</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sequential Upper Boundary (Conceptual)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sequential_lower_boundary</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_observations</span><span class="p">),</span> <span class="n">sequential_upper_boundary</span><span class="p">,</span> <span class="n">fixed_critical_value</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_observations</span><span class="p">),</span> <span class="n">sequential_lower_boundary</span><span class="p">,</span> <span class="o">-</span><span class="n">fixed_critical_value</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>


<span class="c1"># Mark a conceptual stopping point for sequential test</span>
<span class="c1"># Find where simulated Z-score crosses sequential boundary</span>
<span class="n">sequential_stop_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">z_scores_simulated</span> <span class="o">&gt;</span> <span class="n">sequential_upper_boundary</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequential_stop_idx</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">stop_point</span> <span class="o">=</span> <span class="n">sequential_stop_idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">stop_point</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Sequential Test Stops Early (Obs </span><span class="si">{</span><span class="n">stop_point</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">stop_point</span><span class="p">,</span> <span class="n">z_scores_simulated</span><span class="p">[</span><span class="n">stop_point</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">stop_point</span> <span class="o">+</span> <span class="mi">5</span><span class="p">,</span> <span class="n">z_scores_simulated</span><span class="p">[</span><span class="n">stop_point</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s1">&#39;Early Stop&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;purple&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Conceptual Comparison: Fixed Horizon vs. Sequential Testing&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Observations / Time&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Test Statistic (Z-score)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># Adjust limits as needed</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Conceptual Plot: Fixed Horizon vs. Sequential Testing ---
</pre></div>
</div>
<img alt="../../_images/0df7bc22c3023d42d04bc245c065d42c2b65b86dfddad5f9899b5395e0673d07.png" src="../../_images/0df7bc22c3023d42d04bc245c065d42c2b65b86dfddad5f9899b5395e0673d07.png" />
</div>
</div>
<p><strong>Interpretation of the Conceptual Plot:</strong></p>
<ul class="simple">
<li><p>The <strong>red dashed lines</strong> represent the fixed critical values. In a fixed horizon test, you’d only check if the blue line (observed Z-score) crosses these lines at the very end of the experiment.</p></li>
<li><p>The <strong>green solid lines</strong> represent the <em>adjusted</em> critical boundaries for a sequential test. Notice they start wider and converge towards the fixed horizon critical values. This accounts for the multiple peeks.</p></li>
<li><p>The <strong>blue line</strong> shows a simulated observed Z-score.</p></li>
<li><p>The <strong>purple dotted line</strong> and point show where a sequential test <em>could</em> stop early because the observed Z-score crossed the (stricter) sequential boundary, allowing for a decision much sooner than the fixed horizon.</p></li>
</ul>
<p>This visualization highlights the core advantage of sequential testing: the ability to make valid early stopping decisions, leading to more efficient and ethical A/B testing.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</section>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="maximum-likelihood-estimation-mle-and-resampling-techniques">
<h1>Maximum Likelihood Estimation (MLE) and Resampling Techniques<a class="headerlink" href="#maximum-likelihood-estimation-mle-and-resampling-techniques" title="Link to this heading">#</a></h1>
<p>This notebook covers two powerful statistical concepts: Maximum Likelihood Estimation (MLE) for parameter estimation and Resampling Techniques (Bootstrap and Jackknife) for estimating uncertainty and validating models.</p>
<section id="maximum-likelihood-estimation-mle">
<h2>1. Maximum Likelihood Estimation (MLE)<a class="headerlink" href="#maximum-likelihood-estimation-mle" title="Link to this heading">#</a></h2>
<section id="explanation">
<h3>Explanation<a class="headerlink" href="#explanation" title="Link to this heading">#</a></h3>
<p><strong>Maximum Likelihood Estimation (MLE)</strong> is a method of estimating the parameters of a statistical model. The core idea behind MLE is to find the parameter values that make the observed data <strong>most probable</strong> (i.e., maximize the <strong>likelihood function</strong>).</p>
<p>Imagine you have a dataset and you believe it comes from a certain probability distribution (e.g., Normal, Bernoulli, Poisson). MLE helps you find the specific parameters of that distribution (e.g., mean and standard deviation for Normal, probability of success for Bernoulli) that would make your observed data most likely to occur.</p>
<p><strong>Purpose:</strong></p>
<ul class="simple">
<li><p><strong>Parameter Estimation:</strong> It’s a widely used method to estimate unknown parameters of a probability distribution or statistical model from observed data.</p></li>
<li><p><strong>Model Fitting:</strong> It provides a principled way to fit models to data.</p></li>
<li><p><strong>Foundation:</strong> It forms the basis for many advanced statistical methods and machine learning algorithms.</p></li>
</ul>
</section>
<section id="mathematical-intuition">
<h3>Mathematical Intuition<a class="headerlink" href="#mathematical-intuition" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><strong>Likelihood Function (<span class="math notranslate nohighlight">\(L(\theta | \mathbf{x})\)</span>):</strong></p>
<ul class="simple">
<li><p>Let’s say your data consists of <span class="math notranslate nohighlight">\(n\)</span> independent and identically distributed (i.i.d.) observations: <span class="math notranslate nohighlight">\(\mathbf{x} = (x_1, x_2, \dots, x_n)\)</span>.</p></li>
<li><p>You assume these observations come from a probability distribution with parameters <span class="math notranslate nohighlight">\(\theta\)</span> (e.g., <span class="math notranslate nohighlight">\(\theta = (\mu, \sigma)\)</span> for a Normal distribution, or <span class="math notranslate nohighlight">\(\theta = p\)</span> for a Bernoulli distribution).</p></li>
<li><p>The probability density function (PDF) or probability mass function (PMF) for a single observation <span class="math notranslate nohighlight">\(x_i\)</span> given parameters <span class="math notranslate nohighlight">\(\theta\)</span> is <span class="math notranslate nohighlight">\(f(x_i | \theta)\)</span>.</p></li>
<li><p>Since the observations are i.i.d., the <strong>likelihood function</strong> is the product of the individual PDFs/PMFs:
$<span class="math notranslate nohighlight">\(L(\theta | \mathbf{x}) = f(x_1 | \theta) \cdot f(x_2 | \theta) \cdot \dots \cdot f(x_n | \theta) = \prod_{i=1}^{n} f(x_i | \theta)\)</span>$</p></li>
<li><p>The likelihood function is viewed as a function of the parameters <span class="math notranslate nohighlight">\(\theta\)</span>, with the observed data <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> being fixed. We want to find the <span class="math notranslate nohighlight">\(\theta\)</span> that maximizes this function.</p></li>
</ul>
</li>
<li><p><strong>Log-Likelihood Function (<span class="math notranslate nohighlight">\(\ln L(\theta | \mathbf{x})\)</span>):</strong></p>
<ul class="simple">
<li><p>Maximizing the product of many small probabilities can be computationally challenging and prone to underflow (numbers becoming too small for computer representation).</p></li>
<li><p>Taking the natural logarithm of the likelihood function converts the product into a sum:
$<span class="math notranslate nohighlight">\(\ln L(\theta | \mathbf{x}) = \ln \left( \prod_{i=1}^{n} f(x_i | \theta) \right) = \sum_{i=1}^{n} \ln f(x_i | \theta)\)</span>$</p></li>
<li><p>Maximizing the log-likelihood is equivalent to maximizing the likelihood, because the logarithm is a monotonically increasing function. It’s much easier to work with sums than products, especially when taking derivatives.</p></li>
</ul>
</li>
<li><p><strong>Estimating Parameters from Data:</strong></p>
<ul class="simple">
<li><p>To find the parameters <span class="math notranslate nohighlight">\(\hat{\theta}_{\text{MLE}}\)</span> that maximize the log-likelihood, we use calculus:</p>
<ol class="arabic simple">
<li><p><strong>Take the partial derivative</strong> of the log-likelihood function with respect to each parameter in <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
<li><p><strong>Set these derivatives to zero</strong> and solve the resulting equations. These are called the “likelihood equations.”</p></li>
<li><p>(Optionally) Verify that these solutions correspond to a maximum (using second derivatives).</p></li>
</ol>
</li>
</ul>
</li>
</ol>
<p><strong>Problem Statement: Estimating the Probability of Success (p) for a Bernoulli Distribution</strong></p>
<p>You flip a coin 10 times and observe the following sequence of outcomes (1 for Heads, 0 for Tails):
<span class="math notranslate nohighlight">\(\mathbf{x} = (1, 0, 1, 1, 0, 1, 0, 1, 1, 0)\)</span></p>
<p>Assuming this coin follows a Bernoulli distribution, what is the Maximum Likelihood Estimate for the probability of getting a Head (<span class="math notranslate nohighlight">\(p\)</span>)?</p>
<p><strong>Manual Calculation:</strong></p>
<ol class="arabic">
<li><p><strong>Define the Bernoulli PMF:</strong>
For a single flip <span class="math notranslate nohighlight">\(x_i\)</span>:
<span class="math notranslate nohighlight">\(f(x_i | p) = p^{x_i} (1-p)^{1-x_i}\)</span></p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(x_i = 1\)</span> (Head), <span class="math notranslate nohighlight">\(f(1|p) = p^1 (1-p)^0 = p\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(x_i = 0\)</span> (Tail), <span class="math notranslate nohighlight">\(f(0|p) = p^0 (1-p)^1 = 1-p\)</span></p></li>
</ul>
</li>
<li><p><strong>Construct the Likelihood Function:</strong>
We have 6 Heads (1s) and 4 Tails (0s) in 10 flips.
<span class="math notranslate nohighlight">\(L(p | \mathbf{x}) = p \cdot (1-p) \cdot p \cdot p \cdot (1-p) \cdot p \cdot (1-p) \cdot p \cdot p \cdot (1-p)\)</span>
<span class="math notranslate nohighlight">\(L(p | \mathbf{x}) = p^6 (1-p)^4\)</span></p></li>
<li><p><strong>Construct the Log-Likelihood Function:</strong>
<span class="math notranslate nohighlight">\(\ln L(p | \mathbf{x}) = \ln(p^6 (1-p)^4)\)</span>
<span class="math notranslate nohighlight">\(\ln L(p | \mathbf{x}) = 6 \ln(p) + 4 \ln(1-p)\)</span></p></li>
<li><p><strong>Take the Derivative with respect to p and Set to Zero:</strong>
<span class="math notranslate nohighlight">\(\frac{d}{dp} \ln L(p | \mathbf{x}) = \frac{6}{p} - \frac{4}{1-p}\)</span></p>
<p>Set derivative to zero:
<span class="math notranslate nohighlight">\(\frac{6}{p} - \frac{4}{1-p} = 0\)</span>
<span class="math notranslate nohighlight">\(\frac{6}{p} = \frac{4}{1-p}\)</span>
<span class="math notranslate nohighlight">\(6(1-p) = 4p\)</span>
<span class="math notranslate nohighlight">\(6 - 6p = 4p\)</span>
<span class="math notranslate nohighlight">\(6 = 10p\)</span>
<span class="math notranslate nohighlight">\(p = \frac{6}{10} = \mathbf{0.6}\)</span></p>
</li>
</ol>
<p><strong>Interpretation:</strong> The Maximum Likelihood Estimate for the probability of getting a Head is 0.6. This intuitively makes sense: out of 10 flips, 6 were Heads, so the most “likely” probability of getting a Head is simply the observed proportion.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">bernoulli</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">minimize_scalar</span> <span class="c1"># For numerical optimization example</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.sans-serif&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DejaVu Sans&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- Maximum Likelihood Estimation (MLE) ---&quot;</span><span class="p">)</span>

<span class="c1"># Problem Statement Data</span>
<span class="n">observed_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">num_heads</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">observed_data</span><span class="p">)</span>
<span class="n">num_flips</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">observed_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Observed Data: </span><span class="si">{</span><span class="n">observed_data</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of Heads: </span><span class="si">{</span><span class="n">num_heads</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of Flips: </span><span class="si">{</span><span class="n">num_flips</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Define the Log-Likelihood function for Bernoulli</span>
<span class="c1"># We want to MAXIMIZE this, but optimization functions often MINIMIZE, so we minimize the negative log-likelihood</span>
<span class="k">def</span><span class="w"> </span><span class="nf">neg_log_likelihood_bernoulli</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="mi">0</span> <span class="o">&lt;</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span> <span class="c1"># Ensure p is within valid range</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="c1"># For Bernoulli, log-likelihood is sum(x_i * log(p) + (1-x_i) * log(1-p))</span>
    <span class="c1"># Which simplifies to num_heads * log(p) + num_tails * log(1-p)</span>
    <span class="n">n_heads</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">n_tails</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">n_heads</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">n_heads</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">n_tails</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">))</span>

<span class="c1"># --- Plotting Likelihood and Log-Likelihood ---</span>
<span class="n">p_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> <span class="c1"># Range of possible &#39;p&#39; values</span>

<span class="n">likelihood_values</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">log_likelihood_values</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">p_values</span><span class="p">:</span>
    <span class="c1"># Calculate likelihood: p^num_heads * (1-p)^num_tails</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="p">(</span><span class="n">p</span><span class="o">**</span><span class="n">num_heads</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">num_flips</span> <span class="o">-</span> <span class="n">num_heads</span><span class="p">))</span>
    <span class="n">likelihood_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">likelihood</span><span class="p">)</span>
    
    <span class="c1"># Calculate log-likelihood: num_heads * log(p) + num_tails * log(1-p)</span>
    <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">num_heads</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">num_flips</span> <span class="o">-</span> <span class="n">num_heads</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>
    <span class="n">log_likelihood_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_likelihood</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Plot Likelihood Function</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_values</span><span class="p">,</span> <span class="n">likelihood_values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">num_heads</span><span class="o">/</span><span class="n">num_flips</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;MLE (p=</span><span class="si">{</span><span class="n">num_heads</span><span class="o">/</span><span class="n">num_flips</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Likelihood Function for Bernoulli Parameter (p)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Parameter p&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Likelihood&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>

<span class="c1"># Plot Log-Likelihood Function</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_values</span><span class="p">,</span> <span class="n">log_likelihood_values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightcoral&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">num_heads</span><span class="o">/</span><span class="n">num_flips</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;MLE (p=</span><span class="si">{</span><span class="n">num_heads</span><span class="o">/</span><span class="n">num_flips</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Log-Likelihood Function for Bernoulli Parameter (p)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Parameter p&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Log-Likelihood&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Numerical optimization to find MLE (confirming manual calculation)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">minimize_scalar</span><span class="p">(</span><span class="n">neg_log_likelihood_bernoulli</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">observed_data</span><span class="p">,),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;bounded&#39;</span><span class="p">)</span>
<span class="n">mle_p_numerical</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Manual MLE for p: </span><span class="si">{</span><span class="n">num_heads</span><span class="o">/</span><span class="n">num_flips</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Numerical MLE for p: </span><span class="si">{</span><span class="n">mle_p_numerical</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Maximum Likelihood Estimation (MLE) ---
Observed Data: [1 0 1 1 0 1 0 1 1 0]
Number of Heads: 6
Number of Flips: 10
</pre></div>
</div>
<img alt="../../_images/17c30e1b581ecbcd6d31f5562ec92756c5c389c5af9a4c1811ae2b5cadfc74bf.png" src="../../_images/17c30e1b581ecbcd6d31f5562ec92756c5c389c5af9a4c1811ae2b5cadfc74bf.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Manual MLE for p: 0.600
Numerical MLE for p: 0.600
</pre></div>
</div>
</div>
</div>
<p><strong>Interpretation of MLE Plots:</strong></p>
<ul class="simple">
<li><p><strong>Likelihood Function Plot:</strong> Shows a curve that peaks at the value of <span class="math notranslate nohighlight">\(p\)</span> that makes the observed data most probable.</p></li>
<li><p><strong>Log-Likelihood Function Plot:</strong> Shows a similar curve, but often smoother and easier to work with numerically, also peaking at the same MLE value.
These plots visually confirm that the calculated MLE of <span class="math notranslate nohighlight">\(p=0.6\)</span> is indeed the value that maximizes both the likelihood and log-likelihood of observing the given coin flip sequence.</p></li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="resampling-techniques">
<h2>2. Resampling Techniques<a class="headerlink" href="#resampling-techniques" title="Link to this heading">#</a></h2>
<p>Resampling methods are powerful techniques that involve repeatedly drawing samples from a dataset and fitting a model (or calculating a statistic) on these samples. They are primarily used for:</p>
<ol class="arabic simple">
<li><p><strong>Estimating the precision of sample statistics</strong> (e.g., standard errors, confidence intervals).</p></li>
<li><p><strong>Validating models</strong> by evaluating their performance on unseen data.</p></li>
<li><p><strong>Estimating bias</strong> of an estimator.</p></li>
</ol>
<section id="bootstrapping">
<h3>2.1. Bootstrapping<a class="headerlink" href="#bootstrapping" title="Link to this heading">#</a></h3>
<p><strong>Explanation:</strong>
Bootstrapping is a non-parametric resampling technique used to estimate the sampling distribution of a statistic by repeatedly re-sampling <strong>with replacement</strong> from the <em>observed</em> dataset. It’s particularly useful when the theoretical distribution of a statistic is unknown or difficult to derive, or when assumptions required for analytical methods (like normality) are not met.</p>
<p>The core idea is that the observed sample can be treated as a proxy for the entire population. By drawing many “bootstrap samples” from this observed sample (with replacement), we can simulate the process of drawing samples from the actual population.</p>
<p><strong>Steps for Bootstrapping:</strong></p>
<ol class="arabic simple">
<li><p><strong>Original Sample:</strong> Start with your original dataset of <span class="math notranslate nohighlight">\(N\)</span> observations.</p></li>
<li><p><strong>Bootstrap Samples:</strong> Create a large number (<span class="math notranslate nohighlight">\(B\)</span>, typically 1,000 to 10,000) of new samples, called “bootstrap samples.” Each bootstrap sample is created by randomly drawing <span class="math notranslate nohighlight">\(N\)</span> observations <em>with replacement</em> from your original sample. This means some observations might appear multiple times in a bootstrap sample, while others might not appear at all.</p></li>
<li><p><strong>Calculate Statistic:</strong> For each bootstrap sample, calculate the statistic of interest (e.g., mean, median, standard deviation, regression coefficient, correlation).</p></li>
<li><p><strong>Bootstrap Distribution:</strong> The collection of these <span class="math notranslate nohighlight">\(B\)</span> calculated statistics forms the “bootstrap distribution” of your statistic.</p></li>
<li><p><strong>Inference:</strong> Use this bootstrap distribution to estimate the standard error of the statistic, construct confidence intervals, or perform hypothesis tests.</p></li>
</ol>
<p><strong>Why use it?</strong></p>
<ul class="simple">
<li><p>Estimates standard errors and confidence intervals for complex statistics where analytical formulas are unavailable (e.g., median, quantiles, specific regression coefficients in complex models).</p></li>
<li><p>Does not require assumptions about the underlying population distribution (non-parametric).</p></li>
</ul>
<hr class="docutils" />
<section id="example-problem-statement-estimating-confidence-interval-for-median-income-bootstrap">
<h4><strong>Example Problem Statement: Estimating Confidence Interval for Median Income (Bootstrap)</strong><a class="headerlink" href="#example-problem-statement-estimating-confidence-interval-for-median-income-bootstrap" title="Link to this heading">#</a></h4>
<p>A small startup has collected income data from its first 10 employees (in lakhs INR per annum):
<code class="docutils literal notranslate"><span class="pre">[7,</span> <span class="pre">8,</span> <span class="pre">9,</span> <span class="pre">10,</span> <span class="pre">11,</span> <span class="pre">12,</span> <span class="pre">13,</span> <span class="pre">14,</span> <span class="pre">15,</span> <span class="pre">60]</span></code></p>
<p>The founder wants to know the <strong>median income</strong> and a <strong>90% confidence interval</strong> for this median. The outlier (60 lakhs) makes the mean sensitive, and the small sample size might violate assumptions for standard parametric methods to estimate the median’s confidence interval. Bootstrapping is a good fit.</p>
<p><strong>Manual Calculation (Conceptual &amp; Simplified for 3 Bootstrap Samples):</strong></p>
<p>Original Data (N=10): <code class="docutils literal notranslate"><span class="pre">[7,</span> <span class="pre">8,</span> <span class="pre">9,</span> <span class="pre">10,</span> <span class="pre">11,</span> <span class="pre">12,</span> <span class="pre">13,</span> <span class="pre">14,</span> <span class="pre">15,</span> <span class="pre">60]</span></code>
Original Median of Original Data: Sorting gives <code class="docutils literal notranslate"><span class="pre">[7,</span> <span class="pre">8,</span> <span class="pre">9,</span> <span class="pre">10,</span> <span class="pre">11,</span> <span class="pre">12,</span> <span class="pre">13,</span> <span class="pre">14,</span> <span class="pre">15,</span> <span class="pre">60]</span></code>. Median = <span class="math notranslate nohighlight">\((11+12)/2 = 11.5\)</span>.</p>
<p>Let’s manually perform 3 bootstrap samples (in reality, you’d do 1000s):</p>
<ul class="simple">
<li><p><strong>Bootstrap Sample 1:</strong> (drawing 10 values with replacement)
Suppose we draw: <code class="docutils literal notranslate"><span class="pre">[10,</span> <span class="pre">7,</span> <span class="pre">60,</span> <span class="pre">12,</span> <span class="pre">10,</span> <span class="pre">15,</span> <span class="pre">7,</span> <span class="pre">14,</span> <span class="pre">11,</span> <span class="pre">13]</span></code>
Sorted: <code class="docutils literal notranslate"><span class="pre">[7,</span> <span class="pre">7,</span> <span class="pre">10,</span> <span class="pre">10,</span> <span class="pre">11,</span> <span class="pre">12,</span> <span class="pre">13,</span> <span class="pre">14,</span> <span class="pre">15,</span> <span class="pre">60]</span></code>
Median of Sample 1: <span class="math notranslate nohighlight">\((11+12)/2 = \\mathbf{11.5}\)</span></p></li>
<li><p><strong>Bootstrap Sample 2:</strong>
Suppose we draw: <code class="docutils literal notranslate"><span class="pre">[8,</span> <span class="pre">15,</span> <span class="pre">9,</span> <span class="pre">14,</span> <span class="pre">12,</span> <span class="pre">12,</span> <span class="pre">10,</span> <span class="pre">60,</span> <span class="pre">8,</span> <span class="pre">11]</span></code>
Sorted: <code class="docutils literal notranslate"><span class="pre">[8,</span> <span class="pre">8,</span> <span class="pre">9,</span> <span class="pre">10,</span> <span class="pre">11,</span> <span class="pre">12,</span> <span class="pre">12,</span> <span class="pre">14,</span> <span class="pre">15,</span> <span class="pre">60]</span></code>
Median of Sample 2: <span class="math notranslate nohighlight">\((11+12)/2 = \\mathbf{11.5}\)</span></p></li>
<li><p><strong>Bootstrap Sample 3:</strong>
Suppose we draw: <code class="docutils literal notranslate"><span class="pre">[7,</span> <span class="pre">7,</span> <span class="pre">8,</span> <span class="pre">9,</span> <span class="pre">10,</span> <span class="pre">11,</span> <span class="pre">12,</span> <span class="pre">13,</span> <span class="pre">14,</span> <span class="pre">15]</span></code> (note: 60 was not drawn in this sample)
Sorted: <code class="docutils literal notranslate"><span class="pre">[7,</span> <span class="pre">7,</span> <span class="pre">8,</span> <span class="pre">9,</span> <span class="pre">10,</span> <span class="pre">11,</span> <span class="pre">12,</span> <span class="pre">13,</span> <span class="pre">14,</span> <span class="pre">15]</span></code>
Median of Sample 3: <span class="math notranslate nohighlight">\((10+11)/2 = \\mathbf{10.5}\)</span></p></li>
</ul>
<p>After many (e.g., 1000) such samples, you would have 1000 median values. To find the 90% confidence interval, you’d sort these 1000 medians and find the values at the 5th percentile and 95th percentile.</p>
<p><strong>Python Code for Bootstrapping &amp; Plot:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.sans-serif&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DejaVu Sans&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Bootstrapping Example: Median Income Confidence Interval ---&quot;</span><span class="p">)</span>

<span class="c1"># Original Data</span>
<span class="n">original_data_bootstrap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">60</span><span class="p">])</span>
<span class="n">original_median_bootstrap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">original_data_bootstrap</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original Data: </span><span class="si">{</span><span class="n">original_data_bootstrap</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Median of Original Data: </span><span class="si">{</span><span class="n">original_median_bootstrap</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Number of bootstrap samples</span>
<span class="n">num_bootstraps</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="c1"># Store bootstrap medians</span>
<span class="n">bootstrap_medians</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Perform bootstrapping</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span> <span class="c1"># for reproducibility</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_bootstraps</span><span class="p">):</span>
    <span class="c1"># Draw N samples with replacement from the original data</span>
    <span class="n">bootstrap_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">original_data_bootstrap</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">original_data_bootstrap</span><span class="p">),</span> <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># Calculate the median of the bootstrap sample</span>
    <span class="n">bootstrap_median</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">bootstrap_sample</span><span class="p">)</span>
    <span class="n">bootstrap_medians</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bootstrap_median</span><span class="p">)</span>

<span class="n">bootstrap_medians</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">bootstrap_medians</span><span class="p">)</span>

<span class="c1"># Calculate 90% Confidence Interval</span>
<span class="n">lower_bound_bootstrap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">bootstrap_medians</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">upper_bound_bootstrap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">bootstrap_medians</span><span class="p">,</span> <span class="mi">95</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Bootstrap Statistics (from </span><span class="si">{</span><span class="n">num_bootstraps</span><span class="si">}</span><span class="s2"> samples):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean of Bootstrap Medians: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bootstrap_medians</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Standard Error of Median (Bootstrap): </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">bootstrap_medians</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;90% Confidence Interval for Median: (</span><span class="si">{</span><span class="n">lower_bound_bootstrap</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">upper_bound_bootstrap</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

<span class="c1"># Plotting the Bootstrap Distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">bootstrap_medians</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">original_median_bootstrap</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Original Median: </span><span class="si">{</span><span class="n">original_median_bootstrap</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">lower_bound_bootstrap</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;90% CI Lower Bound: </span><span class="si">{</span><span class="n">lower_bound_bootstrap</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">upper_bound_bootstrap</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;90% CI Upper Bound: </span><span class="si">{</span><span class="n">upper_bound_bootstrap</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Bootstrap Distribution of Medians&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Median Income (Lakhs INR)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Bootstrapping Example: Median Income Confidence Interval ---
Original Data: [ 7  8  9 10 11 12 13 14 15 60]
Median of Original Data: 11.50

Bootstrap Statistics (from 5000 samples):
Mean of Bootstrap Medians: 11.58
Standard Error of Median (Bootstrap): 1.90
90% Confidence Interval for Median: (9.00, 14.00)
</pre></div>
</div>
<img alt="../../_images/cf696d423c52739e879583d0659169908ba6b6d68ac323ad93ba6d577a24dc21.png" src="../../_images/cf696d423c52739e879583d0659169908ba6b6d68ac323ad93ba6d577a24dc21.png" />
</div>
</div>
<p><strong>Interpretation of Bootstrapping Plot:</strong>
The histogram shows the distribution of the median values obtained from thousands of bootstrap samples. This distribution approximates the true sampling distribution of the median. The red dashed line marks the median of the original dataset. The green dotted lines mark the 5th and 95th percentiles of the bootstrap distribution, forming the 90% confidence interval. This visual allows us to understand the variability and uncertainty around our median estimate.</p>
</section>
</section>
<hr class="docutils" />
<section id="jackknife-resampling">
<h3>2.2. Jackknife Resampling<a class="headerlink" href="#jackknife-resampling" title="Link to this heading">#</a></h3>
<p><strong>Explanation:</strong>
The <strong>Jackknife</strong> is another resampling technique used to estimate the bias and standard error of a statistic. Unlike bootstrapping, which resamples with replacement, the Jackknife systematically creates samples by leaving out one observation at a time.</p>
<p><strong>Steps for Jackknife:</strong></p>
<ol class="arabic simple">
<li><p><strong>Original Sample:</strong> Start with your original dataset of <span class="math notranslate nohighlight">\(N\)</span> observations: <span class="math notranslate nohighlight">\(\\mathbf{x} = (x\_1, x\_2, \\dots, x\_N)\)</span>.</p></li>
<li><p><strong>Leave-One-Out Samples:</strong> Create <span class="math notranslate nohighlight">\(N\)</span> “Jackknife samples.” Each Jackknife sample <span class="math notranslate nohighlight">\(x\_{(i)}\)</span> is formed by removing the <span class="math notranslate nohighlight">\(i\)</span>-th observation from the original dataset. So, <span class="math notranslate nohighlight">\(x\_{(1)}\)</span> is the original data without <span class="math notranslate nohighlight">\(x\_1\)</span>, <span class="math notranslate nohighlight">\(x\_{(2)}\)</span> is without <span class="math notranslate nohighlight">\(x\_2\)</span>, and so on. Each Jackknife sample has <span class="math notranslate nohighlight">\(N-1\)</span> observations.</p></li>
<li><p><strong>Calculate Statistic:</strong> For each of the <span class="math notranslate nohighlight">\(N\)</span> Jackknife samples, calculate the statistic of interest (e.g., mean, median, regression coefficient). Let <span class="math notranslate nohighlight">\(\\hat{\\theta}*{(i)}\)</span> be the statistic calculated from sample <span class="math notranslate nohighlight">\(x*{(i)}\)</span>.</p></li>
<li><p><strong>Estimate Bias and Standard Error:</strong></p>
<ul class="simple">
<li><p>Let <span class="math notranslate nohighlight">\(\\hat{\\theta}\)</span> be the statistic calculated from the original full sample.</p></li>
<li><p><strong>Jackknife Estimate of Bias:</strong>
$<span class="math notranslate nohighlight">\(\text{Bias}_{\text{Jackknife}} = (N-1) \left( \frac{1}{N} \sum_{i=1}^{N} \hat{\theta}_{(i)} - \hat{\theta} \right)\)</span>$</p></li>
<li><p><strong>Jackknife Estimate of Standard Error:</strong>
$<span class="math notranslate nohighlight">\(\text{SE}_{\text{Jackknife}} = \sqrt{\frac{N-1}{N} \sum_{i=1}^{N} (\hat{\theta}_{(i)} - \bar{\hat{\theta}})^2}\)</span><span class="math notranslate nohighlight">\(
Where \)</span>\bar{\hat{\theta}} = \frac{1}{N} \sum_{i=1}^{N} \hat{\theta}_{(i)}$ (the mean of the Jackknife estimates).</p></li>
</ul>
</li>
</ol>
<p><strong>Why use it?</strong></p>
<ul class="simple">
<li><p>Provides estimates of bias and standard error, especially for complex statistics.</p></li>
<li><p>Computationally less intensive than bootstrapping for some statistics (as it only requires <span class="math notranslate nohighlight">\(N\)</span> resamples).</p></li>
<li><p>Historically older than bootstrapping, but often less preferred for confidence intervals due to its limitations (e.g., can be inconsistent for non-smooth statistics like the median).</p></li>
</ul>
<hr class="docutils" />
<section id="example-problem-statement-estimating-bias-and-standard-error-of-the-mean-jackknife">
<h4><strong>Example Problem Statement: Estimating Bias and Standard Error of the Mean (Jackknife)</strong><a class="headerlink" href="#example-problem-statement-estimating-bias-and-standard-error-of-the-mean-jackknife" title="Link to this heading">#</a></h4>
<p>Consider a small dataset: <code class="docutils literal notranslate"><span class="pre">[10,</span> <span class="pre">12,</span> <span class="pre">15,</span> <span class="pre">18,</span> <span class="pre">20]</span></code></p>
<p>Estimate the bias and standard error of the mean using the Jackknife method.</p>
<p><strong>Manual Calculation:</strong></p>
<ol class="arabic simple">
<li><p><strong>Original Data:</strong> <span class="math notranslate nohighlight">\(\\mathbf{x} = [10, 12, 15, 18, 20]\)</span></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(N = 5\)</span></p></li>
<li><p><strong>Original Mean (<span class="math notranslate nohighlight">\(\\hat{\\theta}\)</span>):</strong> <span class="math notranslate nohighlight">\(\\frac{10+12+15+18+20}{5} = \\frac{75}{5} = \\mathbf{15}\)</span></p></li>
</ul>
</li>
<li><p><strong>Leave-One-Out Samples and Their Means (<span class="math notranslate nohighlight">\(\\hat{\\theta}\_{(i)}\)</span>):</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x\_{(1)} = [12, 15, 18, 20]\)</span> ; <span class="math notranslate nohighlight">\(\\hat{\\theta}\_{(1)} = (12+15+18+20)/4 = 65/4 = \\mathbf{16.25}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x\_{(2)} = [10, 15, 18, 20]\)</span> ; <span class="math notranslate nohighlight">\(\\hat{\\theta}\_{(2)} = (10+15+18+20)/4 = 63/4 = \\mathbf{15.75}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x\_{(3)} = [10, 12, 18, 20]\)</span> ; <span class="math notranslate nohighlight">\(\\hat{\\theta}\_{(3)} = (10+12+18+20)/4 = 60/4 = \\mathbf{15.00}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x\_{(4)} = [10, 12, 15, 20]\)</span> ; <span class="math notranslate nohighlight">\(\\hat{\\theta}\_{(4)} = (10+12+15+20)/4 = 57/4 = \\mathbf{14.25}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x\_{(5)} = [10, 12, 15, 18]\)</span> ; <span class="math notranslate nohighlight">\(\\hat{\\theta}\_{(5)} = (10+12+15+18)/4 = 55/4 = \\mathbf{13.75}\)</span></p></li>
</ul>
</li>
<li><p><strong>Calculate Mean of Jackknife Estimates (<span class="math notranslate nohighlight">\(\\bar{\\hat{\\theta}}\)</span>):</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\\bar{\\hat{\\theta}} = (16.25 + 15.75 + 15.00 + 14.25 + 13.75) / 5 = 75 / 5 = \\mathbf{15}\)</span></p></li>
</ul>
</li>
<li><p><strong>Calculate Jackknife Bias:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\\text{Bias}\_{\\text{Jackknife}} = (N-1) \\left( \\bar{\\hat{\\theta}} - \\hat{\\theta} \\right)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\\text{Bias}\_{\\text{Jackknife}} = (5-1) \\left( 15 - 15 \\right) = 4 \\times 0 = \\mathbf{0}\)</span></p></li>
<li><p><em>(For the mean, the Jackknife bias estimate is always 0, which is a known property. This is not true for all statistics.)</em></p></li>
</ul>
</li>
<li><p><strong>Calculate Jackknife Standard Error:</strong></p>
<ul class="simple">
<li><p>First, calculate <span class="math notranslate nohighlight">\(\\sum\_{i=1}^{N} (\\hat{\\theta}\_{(i)} - \\bar{\\hat{\\theta}})^2\)</span>:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\((16.25 - 15)^2 = 1.25^2 = 1.5625\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((15.75 - 15)^2 = 0.75^2 = 0.5625\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((15.00 - 15)^2 = 0^2 = 0.0000\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((14.25 - 15)^2 = (-0.75)^2 = 0.5625\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((13.75 - 15)^2 = (-1.25)^2 = 1.5625\)</span></p></li>
<li><p>Sum of squared differences = <span class="math notranslate nohighlight">\(1.5625 + 0.5625 + 0 + 0.5625 + 1.5625 = 4.25\)</span></p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(\\text{SE}*{\\text{Jackknife}} = \\sqrt{\\frac{N-1}{N} \\sum*{i=1}^{N} (\\hat{\\theta}\_{(i)} - \\bar{\\hat{\\theta}})^2}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\\text{SE}\_{\\text{Jackknife}} = \\sqrt{\\frac{5-1}{5} \\times 4.25} = \\sqrt{\\frac{4}{5} \\times 4.25} = \\sqrt{0.8 \\times 4.25} = \\sqrt{3.4} \\approx \\mathbf{1.8439}\)</span></p></li>
</ul>
</li>
</ol>
<p><em>(Compare to analytical standard error of the mean: <span class="math notranslate nohighlight">\(s/\\sqrt{N}\)</span>. Sample std dev for this data is <span class="math notranslate nohighlight">\(\\approx 3.708\)</span>. So <span class="math notranslate nohighlight">\(3.708/\\sqrt{5} \\approx 1.658\)</span>. Jackknife is an approximation.)</em></p>
<p><strong>Python Code for Jackknife &amp; Plot:</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.family&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;sans-serif&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.sans-serif&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;DejaVu Sans&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Jackknife Resampling Example: Mean Standard Error and Bias ---&quot;</span><span class="p">)</span>

<span class="c1"># Original Data</span>
<span class="n">original_data_jackknife</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">20</span><span class="p">])</span>
<span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">original_data_jackknife</span><span class="p">)</span>
<span class="n">original_mean_jackknife</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">original_data_jackknife</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original Data: </span><span class="si">{</span><span class="n">original_data_jackknife</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original Mean: </span><span class="si">{</span><span class="n">original_mean_jackknife</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Store Jackknife estimates</span>
<span class="n">jackknife_estimates</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Perform Jackknife resampling</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="c1"># Create leave-one-out sample</span>
    <span class="n">jackknife_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">original_data_jackknife</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
    <span class="c1"># Calculate the statistic (mean in this case)</span>
    <span class="n">jackknife_estimate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">jackknife_sample</span><span class="p">)</span>
    <span class="n">jackknife_estimates</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">jackknife_estimate</span><span class="p">)</span>

<span class="n">jackknife_estimates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">jackknife_estimates</span><span class="p">)</span>

<span class="c1"># Calculate mean of Jackknife estimates</span>
<span class="n">mean_jackknife_estimates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">jackknife_estimates</span><span class="p">)</span>

<span class="c1"># Calculate Jackknife Bias</span>
<span class="n">jackknife_bias</span> <span class="o">=</span> <span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">mean_jackknife_estimates</span> <span class="o">-</span> <span class="n">original_mean_jackknife</span><span class="p">)</span>

<span class="c1"># Calculate Jackknife Standard Error</span>
<span class="n">sum_sq_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">jackknife_estimates</span> <span class="o">-</span> <span class="n">mean_jackknife_estimates</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">jackknife_se</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(((</span><span class="n">N</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="n">sum_sq_diff</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Jackknife Estimates (Means of Leave-One-Out Samples): </span><span class="si">{</span><span class="n">jackknife_estimates</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean of Jackknife Estimates: </span><span class="si">{</span><span class="n">mean_jackknife_estimates</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jackknife Bias: </span><span class="si">{</span><span class="n">jackknife_bias</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jackknife Standard Error: </span><span class="si">{</span><span class="n">jackknife_se</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Plotting the Jackknife Distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">jackknife_estimates</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightcoral&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">original_mean_jackknife</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Original Mean: </span><span class="si">{</span><span class="n">original_mean_jackknife</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">mean_jackknife_estimates</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Mean of Jackknife Estimates: </span><span class="si">{</span><span class="n">mean_jackknife_estimates</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Jackknife Estimates (Means)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Mean Value&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- Jackknife Resampling Example: Mean Standard Error and Bias ---
Original Data: [10 12 15 18 20]
Original Mean: 15.00

Jackknife Estimates (Means of Leave-One-Out Samples): [16.25 15.75 15.   14.25 13.75]
Mean of Jackknife Estimates: 15.00
Jackknife Bias: 0.0000
Jackknife Standard Error: 1.8439
</pre></div>
</div>
<img alt="../../_images/46bf25709836f8bd3aa793e3689d24cc3ba7df283e1487ea382e519e9b27bc4f.png" src="../../_images/46bf25709836f8bd3aa793e3689d24cc3ba7df283e1487ea382e519e9b27bc4f.png" />
</div>
</div>
<p><strong>Interpretation of Jackknife Plot:</strong>
The histogram shows the distribution of the mean values obtained from each leave-one-out Jackknife sample. While it’s not a direct sampling distribution like Bootstrap, it provides a visual representation of how the statistic changes when individual data points are removed. The blue dashed line marks the mean of the original dataset, and the green dotted line marks the mean of the Jackknife estimates. For the mean, these will coincide, as the Jackknife bias for the mean is zero. This plot helps understand the variability of the estimate due to individual data points.</p>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Mathematics for Data Science\Statistics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Bayesian Statistics: Concepts and Applications</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#concepts">1. Concepts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prior-probability-p-h">1.1. Prior Probability (<span class="math notranslate nohighlight">\(P(H)\)</span>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#likelihood-p-e-h">1.2. Likelihood (<span class="math notranslate nohighlight">\(P(E|H)\)</span>)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#posterior-probability-p-h-e">1.3. Posterior Probability (<span class="math notranslate nohighlight">\(P(H|E)\)</span>)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#applications">2. Applications</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayes-rule-in-inference">2.1. Bayes’ Rule in Inference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-problem-statement-medical-diagnosis"><strong>Example Problem Statement (Medical Diagnosis):</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-b-testing-bayesian-approach">2.2. A/B Testing (Bayesian Approach)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-problem-statement-website-conversion"><strong>Example Problem Statement (Website Conversion):</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-making-under-uncertainty">2.3. Decision Making Under Uncertainty</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-problem-statement-investment-decision"><strong>Example Problem Statement (Investment Decision):</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-decision-making-conceptual-plot"><strong>Visualizing Decision Making (Conceptual Plot):</strong></a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#a-b-testing-metrics-and-methodologies">A/B Testing Metrics and Methodologies</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lift-p-values-conversion-rates">1. Lift, p-values, Conversion Rates</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversion-rate">1.1. Conversion Rate</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lift-relative-increase">1.2. Lift (Relative Increase)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#p-value">1.3. p-value</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-statement-manual-calculation-conversion-rate-lift"><strong>Problem Statement &amp; Manual Calculation (Conversion Rate &amp; Lift):</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-testing-vs-fixed-horizon-testing">2. Sequential Testing vs. Fixed Horizon Testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fixed-horizon-testing-traditional-a-b-testing">2.1. Fixed Horizon Testing (Traditional A/B Testing)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptual-problem-statement-fixed-horizon"><strong>Conceptual Problem Statement (Fixed Horizon):</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-testing-continuous-monitoring">2.2. Sequential Testing (Continuous Monitoring)</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptual-problem-statement-sequential-testing"><strong>Conceptual Problem Statement (Sequential Testing):</strong></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conceptual-plot-fixed-horizon-vs-sequential-testing"><strong>Conceptual Plot: Fixed Horizon vs. Sequential Testing</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-estimation-mle-and-resampling-techniques">Maximum Likelihood Estimation (MLE) and Resampling Techniques</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood-estimation-mle">1. Maximum Likelihood Estimation (MLE)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explanation">Explanation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-intuition">Mathematical Intuition</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#resampling-techniques">2. Resampling Techniques</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bootstrapping">2.1. Bootstrapping</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-problem-statement-estimating-confidence-interval-for-median-income-bootstrap"><strong>Example Problem Statement: Estimating Confidence Interval for Median Income (Bootstrap)</strong></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jackknife-resampling">2.2. Jackknife Resampling</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-problem-statement-estimating-bias-and-standard-error-of-the-mean-jackknife"><strong>Example Problem Statement: Estimating Bias and Standard Error of the Mean (Jackknife)</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>